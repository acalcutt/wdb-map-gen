#!/usr/bin/env python
"""
Usage:
  import-wikidata [--file=<file>] [--host=<host>] [--port=<port>] [--database=<dbname>] [--user=<user>] [--password=<pw>]
Options:
  --file=<file>       Wikidata latest-all.json.gz file
  --host=<host>       PostGIS host.
  --port=<port>       PostGIS port.
  --database=<dbname> PostGIS database name.
  --user=<user>       PostGIS user.
  --password=<pw>     PostGIS password.
"""
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import psycopg2.extras
from wikidata import etl, osm
from wikidata.cfg import *
import os.path
import sys
import argparse

if __name__ == '__main__':
    print('Importing Wikidata ...')
    parser = argparse.ArgumentParser()
    parser.add_argument("--file")
    parser.add_argument("--host")
    parser.add_argument("--port")
    parser.add_argument("--dbname")
    parser.add_argument("--user")
    parser.add_argument("--password")
    args = parser.parse_args()


    conn = psycopg2.connect(dbname=args.dbname, user=args.user,
                            password=args.password, host=args.host,
                            port=args.port)

    psycopg2.extras.register_hstore(conn)
    cur = conn.cursor()

    print('Recreating {} table'.format(TABLE_NAME))
    etl.empty_table(TABLE_NAME, cur)
    conn.commit()

    if(os.path.exists(args.file)):
        print('Scanning following tables:')
        print(' ', '\n  '.join(sorted(OSM_TABLES)))

        ids = osm.get_ids(OSM_TABLES, cur)
        pages = osm.get_pages(OSM_TABLES, cur)
        print('Found {:,} Wikidata IDs and {:,} Wikipedia pages to '
              'load'.format(len(ids), len(pages)))
        print()

        print('Parsing Wikidata dump {} ...'.format(args.file))
        etl.multi_parse(args.file, ids, pages, cur, conn, TABLE_NAME, LIMIT)

    else:
        print('File {} not found, no Wikidata imported!'.format(args.file))

    cur.close()
    conn.close()
    print()
